# A Generalized Diffusion Model Training Framework

Let’s make score-based diffusion modeling more rigorous.

Suppose we have a dataset made of a single sample $ x_0 $, and we add noise to this sample as follows:

$$
x = x_0 + \sigma \cdot \epsilon
$$

This implies that the probability distribution is:

$$
p(x) = \mathcal{N}(x \mid x_0, \sigma^2)
$$

**But** what if $ x_0 $ is itself sampled from a small Gaussian? After all, most VAEs encode images using non-isotropic Gaussians and then the diffusion process adds noise on top. In this case:

$$
x = x_\textrm{vae} + \sigma_{\text{vae}} \cdot \epsilon + \sigma_{\text{diff}} \cdot \epsilon
$$

which gives:

$$
p(x) = \mathcal{N}\left(x \mid x_0, \sigma_{\text{VAE}}^2 + \sigma_{\text{diff}}^2 \right)
$$

You might think these two processes need separate treatments, but I’ll show you how to hit two pigeons with one stone.

From now on, we’ll consider the case where:

$$
x = x_0 + \sigma \cdot \epsilon
$$

and allow $ \sigma $ to be non-isotropic.


## The Loss Function: From First Principles

How do you choose the loss function? You don’t — nature does it for you.

Given a data point $ x $ and known noise level $ \sigma^2 $, we want to estimate the original distribution of $ x_0 $. That is, we aim to learn parameters $ \mu_\theta $, $ \sigma_\phi $ such that:

$$
q(x_0 \mid x) = \mathcal{N}(x_0 \mid \mu_\theta(x), \sigma_\phi(x)^2)
$$

We then minimize the expected negative log-likelihood:

$$
L = \mathbb{E}_{x \sim p(x)}\left[-\log q(x_0 \mid x)\right]
$$

Which decomposes into:

$$
L = \mathrm{KL}(p \| q) + S(p)
$$

Carrying out the KL divergence calculation, assuming known noise level $ \sigma $, we get:

$$
L = \frac{1}{2} \left[\log \sigma_\phi^2 + \frac{\sigma^2 + (\mu_\theta - x_0)^2}{\sigma_\phi^2} + \log(2\pi) \right]
$$


### Properties of the Loss

At the minimum, the optimal value of $ \sigma_\phi $ satisfies:

$$
\frac{\partial L}{\partial \sigma_\phi} = 0 \quad \Rightarrow \quad \sigma_\phi^2 = \sigma^2 + (\mu_\theta - x_0)^2
$$

So the learned variance converges to the sum of the added noise and the model’s squared prediction error — an adaptive uncertainty estimate.

Also, the gradient with respect to $ \mu_\theta $ is:

$$
\frac{\partial L}{\partial \mu_\theta} = \frac{\mu_\theta - x_0}{\sigma_\phi^2}
$$

This resembles the gradient of the MSE loss, but weighted by the inverse of the expected prediction error.


## The Score Function

The core objective of score-based diffusion models is to estimate the **score function**, defined as:

$$
s(x) = \nabla_x \log p(x)
$$

However, since $ p(x) $ is typically unknown, what we do instead is simulate samples of the form:

$$
x = x_0 + \sigma \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)
$$

Here, $ x_0 $ is a clean data sample, and $ x $ is a noisy version. Under this assumption, the conditional distribution of $ x \mid x_0 $ is:

$$
p(x \mid x_0) = \mathcal{N}(x \mid x_0, \sigma^2)
$$

Since $ x $ is generated by adding Gaussian noise to a fixed $ x_0 $, we can compute the score of this conditional distribution analytically:

$$
\nabla_x \log p(x \mid x_0) = -\frac{x - x_0}{\sigma^2}
$$

So a natural estimator of the **true score** of $ p(x) $ is:

$$
s(x) \approx -\frac{x - x_0}{\sigma^2}
$$

This is the formulation that is used in score matching, after all, the models use only predict $x_0$, so it's "natural" to use this score function

### The Problem with This Formulation

While the standard derivation is elegant, it has several practical limitations:
1. **Wrong $\sigma$**: It assumes that the uncertanty of the prediction is equal to $\sigma$ which is generally wrong.

2. **Numerical instability**: As $ \sigma \to 0 $, the denominator $ \sigma^2 $ becomes very small, making the score explode in magnitude.

3. **Uncertainty mismatch**: In practice, $ x_0 $ may itself be drawn from a distribution, such as the decoder of a VAE where:

   $$
   x_0 = x_\textrm{vae} + \sigma_\textrm{vae}\cdot \epsilon
   $$

   In such cases, treating $ x_0 $ as a point estimate and using its mean in the numerator is an oversimplification.

---

### A Better Score Function

We actually can estimate the score with $q$! After all, $q$ is the best approximation of $p$

$$
s(x) = \nabla_x \log q(x) 
$$


And in the end we get this!

$$
s(x) = \nabla_x \log q(x) = -\frac{x - \mu_\theta(x)}{\sigma_\phi^2(x)}
$$

This form:

- Naturally reduces to the standard formula when $ \sigma_\phi \to 0 $
- Remains stable for small $ \sigma $
- Properly incorporates **epistemic uncertainty** (via $ \sigma_\phi $) from the learned model

# Solving the ODE
TODO
# Preconditioning
TODO